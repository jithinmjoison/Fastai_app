{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMOne7dWPtI4OUoB4nDHSNT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jithinmjoison/Fastai_app/blob/main/Varitional_Autoencoders_July_2024.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LfERUv_PFg7d"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras.backend as K\n",
        "from tensorflow.keras import (layers,  models, datasets, callbacks,losses,optimizers, metrics,)\n",
        "\n",
        "from scipy.stats import norm"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### Parameters\n",
        "IMAGE_SIZE = 32\n",
        "BATCH_SIZE = 100\n",
        "VALIDATION_SPLIT = 0.2\n",
        "EMBEDDING_DIM = 2\n",
        "EPOCHS = 5\n",
        "BETA = 500"
      ],
      "metadata": {
        "id": "8iO18Za8GnZ1"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Preparing the data\n",
        "(x_train, y_train), (x_test, y_test) = datasets.fashion_mnist.load_data()"
      ],
      "metadata": {
        "id": "3zrXH9k1HBvt"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Preprocess the data\n",
        "\n",
        "def preprocess(imgs):\n",
        "  \"\"\"\n",
        "  Normalise and reshape the images\"\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  imgs = imgs.astype(np.float32) / 255.0\n",
        "  imgs = np.pad(imgs, ((0,0),(2,2),(2,2)), constant_values =0.0)\n",
        "  imgs = np.expand_dims( imgs, -1)\n",
        "  return imgs\n",
        "\n"
      ],
      "metadata": {
        "id": "vVfpJR0sH2gK"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train = preprocess(x_train)\n",
        "x_test = preprocess(x_test)"
      ],
      "metadata": {
        "id": "O3e2398dIm-s"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Building the sampling function to ensure smoothness\n",
        "\n",
        "class Sampling(layers.Layer):\n",
        "  def call(self, inputs):\n",
        "        z_mean, z_log_var = inputs\n",
        "        batch = tf.shape(z_mean)[0]\n",
        "        dim = tf.shape(z_mean)[1]\n",
        "        epsilon = K.random_normal(shape=(batch, dim))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon"
      ],
      "metadata": {
        "id": "_TS4b97nJyI3"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Encoder###\n",
        "\n",
        "# Encoder\n",
        "encoder_input = layers.Input(\n",
        "    shape=(IMAGE_SIZE, IMAGE_SIZE, 1), name=\"encoder_input\"\n",
        ")\n",
        "x = layers.Conv2D(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(\n",
        "    encoder_input\n",
        ")\n",
        "x = layers.Conv2D(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "x = layers.Conv2D(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\n",
        "shape_before_flattening = K.int_shape(x)[1:]  # the decoder will need this!\n",
        "\n",
        "x = layers.Flatten()(x)\n",
        "z_mean = layers.Dense(EMBEDDING_DIM, name=\"z_mean\")(x)\n",
        "z_log_var = layers.Dense(EMBEDDING_DIM, name=\"z_log_var\")(x)\n",
        "z = Sampling()([z_mean, z_log_var])\n",
        "\n",
        "encoder = models.Model(encoder_input, [z_mean, z_log_var, z], name=\"encoder\")\n",
        "encoder.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Zh_DSzUKm7q",
        "outputId": "6609039f-a9ca-4553-de04-44bf7611b70c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"encoder\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " encoder_input (InputLayer)  [(None, 32, 32, 1)]          0         []                            \n",
            "                                                                                                  \n",
            " conv2d (Conv2D)             (None, 16, 16, 32)           320       ['encoder_input[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_1 (Conv2D)           (None, 8, 8, 64)             18496     ['conv2d[0][0]']              \n",
            "                                                                                                  \n",
            " conv2d_2 (Conv2D)           (None, 4, 4, 128)            73856     ['conv2d_1[0][0]']            \n",
            "                                                                                                  \n",
            " flatten (Flatten)           (None, 2048)                 0         ['conv2d_2[0][0]']            \n",
            "                                                                                                  \n",
            " z_mean (Dense)              (None, 2)                    4098      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " z_log_var (Dense)           (None, 2)                    4098      ['flatten[0][0]']             \n",
            "                                                                                                  \n",
            " sampling (Sampling)         (None, 2)                    0         ['z_mean[0][0]',              \n",
            "                                                                     'z_log_var[0][0]']           \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 100868 (394.02 KB)\n",
            "Trainable params: 100868 (394.02 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Decoder\n",
        "decoder_input = layers.Input(shape=(EMBEDDING_DIM,), name=\"decoder_input\")\n",
        "x = layers.Dense(np.prod(shape_before_flattening))(decoder_input)\n",
        "x = layers.Reshape(shape_before_flattening)(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    128, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    64, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "x = layers.Conv2DTranspose(\n",
        "    32, (3, 3), strides=2, activation=\"relu\", padding=\"same\"\n",
        ")(x)\n",
        "decoder_output = layers.Conv2D(\n",
        "    1,\n",
        "    (3, 3),\n",
        "    strides=1,\n",
        "    activation=\"sigmoid\",\n",
        "    padding=\"same\",\n",
        "    name=\"decoder_output\",\n",
        ")(x)\n",
        "\n",
        "decoder = models.Model(decoder_input, decoder_output)\n",
        "decoder.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3Ac1lwBJ678",
        "outputId": "9454e8e5-f750-4c72-9739-d9ee30553597"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " decoder_input (InputLayer)  [(None, 2)]               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              6144      \n",
            "                                                                 \n",
            " reshape (Reshape)           (None, 4, 4, 128)         0         \n",
            "                                                                 \n",
            " conv2d_transpose (Conv2DTr  (None, 8, 8, 128)         147584    \n",
            " anspose)                                                        \n",
            "                                                                 \n",
            " conv2d_transpose_1 (Conv2D  (None, 16, 16, 64)        73792     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " conv2d_transpose_2 (Conv2D  (None, 32, 32, 32)        18464     \n",
            " Transpose)                                                      \n",
            "                                                                 \n",
            " decoder_output (Conv2D)     (None, 32, 32, 1)         289       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 246273 (962.00 KB)\n",
            "Trainable params: 246273 (962.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "37T3ff_YJpje"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}